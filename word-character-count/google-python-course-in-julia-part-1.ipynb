{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Google Python course in Julia Part 1: word and character counts\n",
    "As part of teaching myself Python (after doing so half-heartedly for about a year) I completed Google's Python course. Also during that time period, I was learning Julia and mostly using its packages to check the results of various statistical models (`GLM`, `MixedModels`). What is nice about Julia is that it combines the best parts of Python, MATLAB, and R. For current purposes, it shares several data structures with Python.  \n",
    "\n",
    "One goal of mine is to make code and analyses portable across platforms and programs. The Google Python course is good for this, at it instructs how to perform basic tasks (file I/O, counts, low-level tokenization) using base Python. Julia is a good language to port this to, as not only it shares data structures, but also is designed to be fast; something that could be very useful when doing basic NLP-like tasks in batches.  So in order to familiarize myself with Julia and learn how to port things, I will implement the exercises in Julia.  \n",
    "\n",
    "The text used will from the Project Gutenberg version of the most famous work of 19th century novelist Amanda McKittrick Ros, *Irene Iddesleigh*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic exercise 1: word count\n",
    "The first exercise to try in Julia (skipping the string and list ones) is the word count exercise. What we want to do is take a text, import it, store the string(s) from the text, then split the strings and the count the total number of words. To keep things simple, we will take the entire text, i.e., include the header pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import_lines (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function import_lines(text_file)\n",
    "    f = open(text_file)\n",
    "    text_array = readlines(f)\n",
    "    close(f)\n",
    "    return text_array\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4162-element Array{Union(ASCIIString,UTF8String),1}:\n",
       " \"The Project Gutenberg EBook of Irene Iddesleigh, by Amanda McKittrick Ros\\r\\n\"\n",
       " \"\\r\\n\"                                                                         \n",
       " \"This eBook is for the use of anyone anywhere at no cost and with\\r\\n\"         \n",
       " \"almost no restrictions whatsoever.  You may copy it, give it away or\\r\\n\"     \n",
       " \"re-use it under the terms of the Project Gutenberg License included\\r\\n\"      \n",
       " \"with this eBook or online at www.gutenberg.net\\r\\n\"                           \n",
       " \"\\r\\n\"                                                                         \n",
       " \"\\r\\n\"                                                                         \n",
       " \"Title: Irene Iddesleigh\\r\\n\"                                                  \n",
       " \"\\r\\n\"                                                                         \n",
       " \"Author: Amanda McKittrick Ros\\r\\n\"                                            \n",
       " \"\\r\\n\"                                                                         \n",
       " \"Release Date: October 31, 2010 [EBook #34181]\\r\\n\"                            \n",
       " ⋮                                                                              \n",
       " \"unless a copyright notice is included.  Thus, we do not necessarily\\r\\n\"      \n",
       " \"keep eBooks in compliance with any particular paper edition.\\r\\n\"             \n",
       " \"\\r\\n\"                                                                         \n",
       " \"\\r\\n\"                                                                         \n",
       " \"Most people start at our Web site which has the main PG search facility:\\r\\n\" \n",
       " \"\\r\\n\"                                                                         \n",
       " \"     http://www.gutenberg.net\\r\\n\"                                            \n",
       " \"\\r\\n\"                                                                         \n",
       " \"This Web site includes information about Project Gutenberg-tm,\\r\\n\"           \n",
       " \"including how to make donations to the Project Gutenberg Literary\\r\\n\"        \n",
       " \"Archive Foundation, how to help produce our new eBooks, and how to\\r\\n\"       \n",
       " \"subscribe to our email newsletter to hear about new eBooks.\\r\\n\"              "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book = \"/Users/julian/GitHub/google-python-julia/word-character-count/irene-iddesleigh.txt\";\n",
    "\n",
    "irene_iddes = import_lines(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we defined a function that took the location of the book, opened the file, and read in each line so that we have an array (1 line = 1 row). But we still have all the formatng present, and we want to normalize the text by putting it into lowercase. Let's create a new function that will concatenate each line and normalize to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalize_lines (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normalize_lines(text_file)\n",
    "    f = open(text_file)\n",
    "    normalize_text = split(lowercase(string(readlines(f))))\n",
    "    close(f)\n",
    "    return normalize_text\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33660-element Array{SubString{UTF8String},1}:\n",
       " \"union(asciistring,utf8string)[\\\"the\"\n",
       " \"project\"                            \n",
       " \"gutenberg\"                          \n",
       " \"ebook\"                              \n",
       " \"of\"                                 \n",
       " \"irene\"                              \n",
       " \"iddesleigh,\"                        \n",
       " \"by\"                                 \n",
       " \"amanda\"                             \n",
       " \"mckittrick\"                         \n",
       " \"ros\\\\r\\\\n\\\",\\\"\\\\r\\\\n\\\",\\\"this\"      \n",
       " \"ebook\"                              \n",
       " \"is\"                                 \n",
       " ⋮                                    \n",
       " \"and\"                                \n",
       " \"how\"                                \n",
       " \"to\\\\r\\\\n\\\",\\\"subscribe\"             \n",
       " \"to\"                                 \n",
       " \"our\"                                \n",
       " \"email\"                              \n",
       " \"newsletter\"                         \n",
       " \"to\"                                 \n",
       " \"hear\"                               \n",
       " \"about\"                              \n",
       " \"new\"                                \n",
       " \"ebooks.\\\\r\\\\n\\\"]\"                   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_irene_iddes = normalize_lines(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that was closer to what we want. Notice that though whitespace is removed, the carriage return character is still present. Let's use a different function to remove this character in addition to the whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalize_lines (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normalize_lines(text_file)\n",
    "    f = open(text_file)\n",
    "    normalize_text = split(lowercase(string(readall(f))))\n",
    "    close(f)\n",
    "    return normalize_text\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36824-element Array{SubString{UTF8String},1}:\n",
       " \"the\"        \n",
       " \"project\"    \n",
       " \"gutenberg\"  \n",
       " \"ebook\"      \n",
       " \"of\"         \n",
       " \"irene\"      \n",
       " \"iddesleigh,\"\n",
       " \"by\"         \n",
       " \"amanda\"     \n",
       " \"mckittrick\" \n",
       " \"ros\"        \n",
       " \"this\"       \n",
       " \"ebook\"      \n",
       " ⋮            \n",
       " \"how\"        \n",
       " \"to\"         \n",
       " \"subscribe\"  \n",
       " \"to\"         \n",
       " \"our\"        \n",
       " \"email\"      \n",
       " \"newsletter\" \n",
       " \"to\"         \n",
       " \"hear\"       \n",
       " \"about\"      \n",
       " \"new\"        \n",
       " \"ebooks.\"    "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_irene_iddes = normalize_lines(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's more like it. Might not be good for very large text files (I am certain it is not, no matter how optimized Julia is) but it got the representation we want. Now that we have each word in the text, let's create a `Dictionary` (subject to change names in Julia 0.4) to map a word to its count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalize_and_count (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normalize_and_count(text_file)\n",
    "    f = open(text_file)\n",
    "    normalize_text = split(lowercase(string(readall(f))))\n",
    "    close(f)\n",
    "    word_dict = Dict()\n",
    "    for word in normalize_text\n",
    "        if haskey(word_dict, word) == false\n",
    "            word_dict[word] = 1\n",
    "        else\n",
    "            word_dict[word] += 1\n",
    "        end\n",
    "    end\n",
    "    return word_dict\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 7927 entries:\n",
       "  \"madness,\"       => 2\n",
       "  \"knows.\"         => 1\n",
       "  \"dollars,\"       => 1\n",
       "  \"since;\"         => 1\n",
       "  \"contemplate\"    => 1\n",
       "  \"enjoy\"          => 3\n",
       "  \"husband.\"       => 2\n",
       "  \"advertisements\" => 1\n",
       "  \"granted,\"       => 1\n",
       "  \"fight\"          => 2\n",
       "  \"princess\"       => 1\n",
       "  \"read--\\\"was\"    => 1\n",
       "  \"helping\"        => 1\n",
       "  \"whose\"          => 54\n",
       "  \"hurried\"        => 5\n",
       "  \"attendant,\"     => 1\n",
       "  \"propositions\"   => 1\n",
       "  \"began:\"         => 1\n",
       "  \"day,\"           => 8\n",
       "  \"henry\"          => 2\n",
       "  \"loved?\"         => 1\n",
       "  \"borders\"        => 1\n",
       "  \"sweetness,\"     => 1\n",
       "  \"drawers\"        => 1\n",
       "  \"bachelorism\"    => 1\n",
       "  ⋮                => ⋮"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irene_iddes_word_count = normalize_and_count(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2058"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irene_iddes_word_count[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irene_iddes_word_count[\"which\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "key not found: \"despondent\"\nwhile loading In[11], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "key not found: \"despondent\"\nwhile loading In[11], in expression starting on line 1",
      "",
      " in getindex at dict.jl:617"
     ]
    }
   ],
   "source": [
    "irene_iddes_word_count[\"despondent\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that is is essentially what we want for the word count. Closer inspection reveals that punctuation and othe rcharacters have not been removed; I will do that at a later time when I feel more confident about programming these types of things. Next, let's use the same ideas to perform a character count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Basic exercise 2: character count\n",
    "So in the word count portion, we took our text, imported it, and then split on whitespace after converting to lowercase. Using the same idea, whe will now split each word into characters, and count the total number of characters. Notice that there is an additional loop over the split words; this is because after calling `split` for each word in the array, you get an array of the characters in the word entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalize_and_char_count (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normalize_and_char_count(text_file)\n",
    "    f = open(text_file)\n",
    "    normalize_text = split(lowercase(string(readall(f))))\n",
    "    close(f)\n",
    "    char_dict = Dict()\n",
    "    for word in normalize_text\n",
    "        split_word = split(word, \"\")\n",
    "        for char in split_word\n",
    "            if haskey(char_dict, char) == false\n",
    "                char_dict[char] = 1\n",
    "            else\n",
    "                char_dict[char] += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return char_dict\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "irene_iddes_char_count = normalize_and_char_count(book);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15206"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irene_iddes_char_count[\"t\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10508"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irene_iddes_char_count[\"h\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21826"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irene_iddes_char_count[\"e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irene_iddes_char_count[\"z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that worked out well. Aside from using a lot of `for` loops, that was not too bad. The next item is to implement the 'Baby Names' exercise. This involves reading a HTML file, parsing a table, and extracting the name and position of the name from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 0.3.8\n",
      "Commit 79599ad (2015-04-30 23:40 UTC)\n",
      "Platform Info:\n",
      "  System: Darwin (x86_64-apple-darwin13.4.0)\n",
      "  CPU: Intel(R) Core(TM) i5-3210M CPU @ 2.50GHz\n",
      "  WORD_SIZE: 64\n",
      "  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Sandybridge)\n",
      "  LAPACK: libopenblas\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-3.3\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.8",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
